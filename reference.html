
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Reference &#8212; GPT3-Study  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/classic.css" />
    
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Input Encoding" href="encoding.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="encoding.html" title="Input Encoding"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">GPT3-Study  documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Reference</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="reference">
<h1>Reference<a class="headerlink" href="#reference" title="Permalink to this headline">¶</a></h1>
<section id="papers">
<h2>Papers<a class="headerlink" href="#papers" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>The original GPT-3 paper
<a class="reference external" href="https://arxiv.org/abs/2005.14165">Language Models are Few-Shot Learners</a>:
it is the ultimate resource to understand the new techniques applied by Open
AI.</p></li>
<li><p>The GPT-2 paper <a class="reference external" href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">Language Models are Unsupervised Multitask Learners</a>:
the GPT-3 model remains largely the same as the GPT-2 counterpart.</p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a>: introduced
the encoder-decoder transformer, which is the most tricky part of the GPT
model.</p></li>
</ul>
</section>
<section id="implementation">
<h2>Implementation<a class="headerlink" href="#implementation" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://amaarora.github.io/2020/02/18/annotatedGPT2.html">The Annotated GPT-2</a> is an annotated
version of the GPT-2 paper with plenty of <code class="code docutils literal notranslate"><span class="pre">pytorch</span></code> code.</p></li>
<li><p>This <a class="reference external" href="https://github.com/huggingface/pytorch-openai-transformer-lm">GitHub repo</a> is an
<code class="code docutils literal notranslate"><span class="pre">pytorch</span></code> implementation of the GPT-2 by <a class="reference external" href="https://huggingface.co/">Hugging Face</a>.</p></li>
<li><p>Yet another <a class="reference external" href="https://github.com/graykode/gpt-2-Pytorch">GPT-2 implementation</a> via <code class="code docutils literal notranslate"><span class="pre">PyTorch</span></code></p></li>
<li><p><a class="reference external" href="https://nlp.seas.harvard.edu/2018/04/03/attention.html">The Annotated Transformer</a> explains in code
how the transformer is implemented, and is endorsed by the author of “The
Annotated GPT-2”.</p></li>
<li><p>The <code class="code docutils literal notranslate"><span class="pre">PyTorch</span></code> tutorial</p>
<ul>
<li><p><a class="reference external" href="https://pytorch.org/tutorials/beginner/transformer_tutorial.html">tutorial</a> on
training a sequence-to-sequence model that uses the <code class="code docutils literal notranslate"><span class="pre">nn.Transformer</span></code>
module.</p></li>
</ul>
</li>
</ul>
</section>
<section id="other-sources">
<h2>Other Sources<a class="headerlink" href="#other-sources" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>The post <a class="reference external" href="https://dugas.ch/artificial_curiosity/GPT_architecture.html">The GPT-3 Architecture, on a Napkin</a> explains as
detailed as possible on the GPT-3 architecture, which is super useful.</p></li>
<li><p>This <a class="reference external" href="https://www.fullstackpython.com/gpt-3.html">article</a> is an entry
point of several GPT-3 related resources, including application tutorials.</p></li>
<li><p>Jay Alammar’s blog</p>
<ul>
<li><p><a class="reference external" href="https://jalammar.github.io/how-gpt3-works-visualizations-animations/">How GPT3 Works</a></p></li>
<li><p><a class="reference external" href="https://jalammar.github.io/illustrated-gpt2/">The Illustrated GPT-2</a></p></li>
<li><p><a class="reference external" href="https://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a></p></li>
<li><p><a class="reference external" href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">Mechanics of Seq2seq Models With Attention</a></p></li>
</ul>
</li>
</ul>
<p>Back to <a class="reference internal" href="index.html"><span class="doc">GPT3-Study’s Notes</span></a>.</p>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="index.html">Table of Contents</a></h3>
    <ul>
<li><a class="reference internal" href="#">Reference</a><ul>
<li><a class="reference internal" href="#papers">Papers</a></li>
<li><a class="reference internal" href="#implementation">Implementation</a></li>
<li><a class="reference internal" href="#other-sources">Other Sources</a></li>
</ul>
</li>
</ul>

  </div>
  <div>
    <h4>Previous topic</h4>
    <p class="topless"><a href="encoding.html"
                          title="previous chapter">Input Encoding</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/reference.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="encoding.html" title="Input Encoding"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">GPT3-Study  documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Reference</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2022, ZHANG, Meng.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 4.5.0.
    </div>
  </body>
</html>